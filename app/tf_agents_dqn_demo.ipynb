{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "113b576c-ebd1-456a-a2c1-d7bf535d7ec3",
   "metadata": {},
   "source": [
    "# Testing tf-agents library on Wordle Env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab22ce9-f8ed-4b3f-a3d2-fa2e8efffb88",
   "metadata": {},
   "source": [
    "This is a recreation of the TF Agents DQN tutorial:\n",
    "https://www.tensorflow.org/agents/tutorials/1_dqn_tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09e60219-2911-452f-ab16-d3b4d88bb595",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-16 19:17:00.535878: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-02-16 19:17:00.535923: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from wordle_rl import WordleEnv\n",
    "\n",
    "# import gym\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import tf_agents\n",
    "import reverb\n",
    "\n",
    "from tf_agents.agents.dqn import dqn_agent\n",
    "from tf_agents.drivers import py_driver\n",
    "from tf_agents.drivers import dynamic_episode_driver\n",
    "\n",
    "from tf_agents.environments import suite_gym\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.eval import metric_utils\n",
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.networks import sequential\n",
    "from tf_agents.policies import py_tf_eager_policy\n",
    "from tf_agents.policies import random_tf_policy\n",
    "from tf_agents.replay_buffers import reverb_replay_buffer\n",
    "from tf_agents.replay_buffers import reverb_utils\n",
    "from tf_agents.trajectories import trajectory\n",
    "from tf_agents.specs import tensor_spec\n",
    "from tf_agents.utils import common\n",
    "\n",
    "\n",
    "from tf_agents.environments import py_environment\n",
    "from tf_agents.environments import tf_environment\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.environments import utils\n",
    "from tf_agents.specs import array_spec\n",
    "from tf_agents.environments import wrappers\n",
    "from tf_agents.environments import suite_gym\n",
    "from tf_agents.trajectories import time_step as ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4af75efd-1790-4cbd-9666-bb1d6eb973a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0305e9d-b9e8-4775-ad98-72592a20ab54",
   "metadata": {},
   "source": [
    "### 1) Hyperparameters of this demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a22cc740-e5d6-421b-a840-8dec54a7ec26",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iterations = 20000 # @param {type:\"integer\"}\n",
    "\n",
    "initial_collect_steps = 100  # @param {type:\"integer\"}\n",
    "collect_steps_per_iteration = 1 # @param {type:\"integer\"}\n",
    "replay_buffer_max_length = 100000  # @param {type:\"integer\"}\n",
    "\n",
    "batch_size = 64  # @param {type:\"integer\"}\n",
    "learning_rate = 1e-3  # @param {type:\"number\"}\n",
    "log_interval = 200  # @param {type:\"integer\"}\n",
    "\n",
    "num_eval_episodes = 10  # @param {type:\"integer\"}\n",
    "eval_interval = 1000  # @param {type:\"integer\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00283ebb-20e5-4188-b5a7-be553ab22b37",
   "metadata": {},
   "source": [
    "### 2) Convert Gym envs to TFPy envs\n",
    "\n",
    "Two things are happening here:\n",
    "1) We're initializing a separate train and eval env\n",
    "2) We're convering our custom OpenAI Gym env into a TF python env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05c8f560-dabc-4017-ac35-c6df5137c4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = WordleEnv(\"config.json\")\n",
    "env = tf_agents.environments.gym_wrapper.GymWrapper(env)\n",
    "\n",
    "gym_train_env = WordleEnv(\"config.json\")\n",
    "gym_eval_env = WordleEnv(\"config.json\")\n",
    "\n",
    "py_train_env = tf_agents.environments.gym_wrapper.GymWrapper(gym_train_env)\n",
    "py_eval_env = tf_agents.environments.gym_wrapper.GymWrapper(gym_eval_env)\n",
    "\n",
    "train_env = tf_py_environment.TFPyEnvironment(py_train_env)\n",
    "eval_env = tf_py_environment.TFPyEnvironment(py_eval_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e4c021-ccdb-4df1-b800-51a450c2da66",
   "metadata": {},
   "source": [
    "### 3) Define a TF agent\n",
    "\n",
    "TF-Agents library comes with several different algorithms implemented. Here we'll use a DQN. \n",
    "\n",
    "Instantiating a DQN with TF-Agents involves: \n",
    "1) Defining a Q Network object\n",
    "2) Feeding that Q Network to a DQN agent object\n",
    "\n",
    "The \"Q Network\" is a neural network model that takes env state observations as input and computes Q values as output. Q values here are reward probability estimations for given actions in given env states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1917126d-66ec-4822-852c-99b9c67c7e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_layer_params = (100, 50)\n",
    "action_tensor_spec = tensor_spec.from_spec(env.action_spec())\n",
    "num_actions = action_tensor_spec.maximum - action_tensor_spec.minimum + 1\n",
    "\n",
    "# Define a helper function to create Dense layers configured with the right\n",
    "# activation and kernel initializer.\n",
    "def dense_layer(num_units):\n",
    "    return tf.keras.layers.Dense(\n",
    "      num_units,\n",
    "      activation=tf.keras.activations.relu,\n",
    "      kernel_initializer=tf.keras.initializers.VarianceScaling(\n",
    "          scale=2.0, mode='fan_in', distribution='truncated_normal'))\n",
    "\n",
    "# QNetwork consists of a sequence of Dense layers followed by a dense layer\n",
    "# with `num_actions` units to generate one q_value per available action as\n",
    "# its output.\n",
    "dense_layers = [dense_layer(num_units) for num_units in fc_layer_params]\n",
    "q_values_layer = tf.keras.layers.Dense(\n",
    "    num_actions,\n",
    "    activation=None,\n",
    "    kernel_initializer=tf.keras.initializers.RandomUniform(\n",
    "        minval=-0.03, maxval=0.03),\n",
    "    bias_initializer=tf.keras.initializers.Constant(-0.2))\n",
    "q_net = sequential.Sequential(dense_layers + [q_values_layer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8b2211c-46fd-4929-81e0-79bafc9d2932",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-16 19:17:10.403612: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-02-16 19:17:10.403679: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-02-16 19:17:10.403770: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (f5bfd35a90d8): /proc/driver/nvidia/version does not exist\n",
      "2022-02-16 19:17:10.404043: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "train_step_counter = tf.Variable(0)\n",
    "\n",
    "agent = dqn_agent.DqnAgent(\n",
    "    train_env.time_step_spec(),\n",
    "    train_env.action_spec(),\n",
    "    q_network=q_net,\n",
    "    optimizer=optimizer,\n",
    "    td_errors_loss_fn=common.element_wise_squared_loss,\n",
    "    train_step_counter=train_step_counter)\n",
    "\n",
    "agent.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61142671-78f1-4a45-ae49-ffb1e634c244",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.policies.greedy_policy.GreedyPolicy at 0x7f6a44084370>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "314b8cff-37fd-420f-8cac-8a795615e5b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf_agents.policies.epsilon_greedy_policy.EpsilonGreedyPolicy at 0x7f6a44080fd0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.collect_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53541e73-28e8-4165-aca1-cf6bdd62b1a7",
   "metadata": {},
   "source": [
    "### 4) Define a Replay Buffer\n",
    "\n",
    "This is technically optional. The replay buffer will improve data efficiency, that is we will get more information from each game as the replay buffer lets us replay games to see different outcomes from certain states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa2c7f5b-a199-416e-a322-0d3d2049452d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Trajectory(\n",
       "{'action': BoundedTensorSpec(shape=(), dtype=tf.int64, name='action', minimum=array(0), maximum=array(10656)),\n",
       " 'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'next_step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),\n",
       " 'observation': BoundedTensorSpec(shape=(60,), dtype=tf.uint8, name='observation', minimum=array(0, dtype=uint8), maximum=array(29, dtype=uint8)),\n",
       " 'policy_info': (),\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.collect_data_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f858751-d7be-4b1c-b79d-a81ae3060764",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[reverb/cc/platform/tfrecord_checkpointer.cc:150]  Initializing TFRecordCheckpointer in /tmp/tmprlz9zac4.\n",
      "[reverb/cc/platform/tfrecord_checkpointer.cc:386] Loading latest checkpoint from /tmp/tmprlz9zac4\n",
      "[reverb/cc/platform/default/server.cc:71] Started replay server on port 15931\n"
     ]
    }
   ],
   "source": [
    "# table_name = 'uniform_table'\n",
    "# replay_buffer_signature = tensor_spec.from_spec(\n",
    "#       agent.collect_data_spec)\n",
    "# replay_buffer_signature = tensor_spec.add_outer_dim(\n",
    "#     replay_buffer_signature)\n",
    "\n",
    "# table = reverb.Table(\n",
    "#     table_name,\n",
    "#     max_size=replay_buffer_max_length,\n",
    "#     sampler=reverb.selectors.Uniform(),\n",
    "#     remover=reverb.selectors.Fifo(),\n",
    "#     rate_limiter=reverb.rate_limiters.MinSize(1),\n",
    "#     signature=replay_buffer_signature)\n",
    "\n",
    "# reverb_server = reverb.Server([table])\n",
    "\n",
    "# replay_buffer = reverb_replay_buffer.ReverbReplayBuffer(\n",
    "#     agent.collect_data_spec,\n",
    "#     table_name=table_name,\n",
    "#     sequence_length=2,\n",
    "#     local_server=reverb_server)\n",
    "\n",
    "# rb_observer = reverb_utils.ReverbAddTrajectoryObserver(\n",
    "#   replay_buffer.py_client,\n",
    "#   table_name,\n",
    "#   sequence_length=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3602ccb5-3a70-41f1-b0f0-4400add554e8",
   "metadata": {},
   "source": [
    "### 5) Train our agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4645968-4c8d-47a1-9feb-29fedaa21645",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_step = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "193081fb-7b19-4d70-9629-0702627807ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.drivers import dynamic_step_driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a442e937-be3c-4cae-bab0-23c4ece8b81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer_capacity = 1000\n",
    "\n",
    "replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
    "    agent.collect_data_spec,\n",
    "    batch_size=train_env.batch_size,\n",
    "    max_length=replay_buffer_capacity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89d4f4d8-8092-4ea1-9503-52affa206089",
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_observer = [replay_buffer.add_batch]\n",
    "\n",
    "collect_steps_per_iteration = 10\n",
    "collect_op = dynamic_step_driver.DynamicStepDriver(\n",
    "  train_env,\n",
    "  agent.collect_policy,\n",
    "  observers=replay_observer,\n",
    "  num_steps=collect_steps_per_iteration).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfbd0533-505d-463e-a598-4441f5ff1b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_avg_return(environment, policy, num_episodes=10):\n",
    "\n",
    "    total_return = 0.0\n",
    "    for _ in range(num_episodes):\n",
    "\n",
    "        time_step = environment.reset()\n",
    "        episode_return = 0.0\n",
    "\n",
    "        while not time_step.is_last():\n",
    "            action_step = policy.action(time_step)\n",
    "            time_step = environment.step(action_step.action)\n",
    "            episode_return += time_step.reward\n",
    "        total_return += episode_return\n",
    "\n",
    "    avg_return = total_return / num_episodes\n",
    "    return avg_return.numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e4a495c-9a44-4cf2-b796-ec224ccf34e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional) Optimize by wrapping some of the code in a graph using TF function.\n",
    "agent.train = common.function(agent.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b58b96-c9d0-4406-a034-d35afd386dc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "num_iterations = 10000 # @param {type:\"integer\"}\n",
    "\n",
    "initial_collect_steps = 100  # @param {type:\"integer\"}\n",
    "collect_steps_per_iteration = 1 # @param {type:\"integer\"}\n",
    "replay_buffer_max_length = 10000  # @param {type:\"integer\"}\n",
    "\n",
    "batch_size = 64  # @param {type:\"integer\"}\n",
    "learning_rate = 1e-3  # @param {type:\"number\"}\n",
    "log_interval = 4000  # @param {type:\"integer\"}\n",
    "\n",
    "num_eval_episodes = 10  # @param {type:\"integer\"}\n",
    "eval_interval = 1000  # @param {type:\"integer\"}\n",
    "\n",
    "\n",
    "# Reset the train step.\n",
    "agent.train_step_counter.assign(0)\n",
    "\n",
    "# Evaluate the agent's policy once before training.\n",
    "avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
    "returns = [avg_return]\n",
    "\n",
    "# Reset the environment.\n",
    "time_step = train_env.reset()\n",
    "\n",
    "# Create a driver to collect experience.\n",
    "collect_steps_per_iteration = 10\n",
    "collect_op = dynamic_step_driver.DynamicStepDriver(\n",
    "  train_env,\n",
    "  agent.collect_policy,\n",
    "  observers=replay_observer,\n",
    "  num_steps=collect_steps_per_iteration)\n",
    "\n",
    "dataset = replay_buffer.as_dataset(\n",
    "    num_parallel_calls=3,\n",
    "    sample_batch_size=batch_size,\n",
    "    num_steps=2)\n",
    "\n",
    "iterator = iter(dataset)\n",
    "\n",
    "for _ in tqdm(range(num_iterations)):\n",
    "\n",
    "    # Collect a few steps and save to the replay buffer.\n",
    "    time_step, _ = collect_op.run(time_step)\n",
    "\n",
    "    # Sample a batch of data from the buffer and update the agent's network.\n",
    "    # print(time_step)\n",
    "    experience, unused_info = next(iterator)\n",
    "    # print(experience)\n",
    "    train_loss = agent.train(experience).loss\n",
    "    # print(train_loss)\n",
    "    step = agent.train_step_counter.numpy()\n",
    "    # print(step)\n",
    "    if step % log_interval == 0:\n",
    "        print('step = {0}: loss = {1}'.format(step, train_loss))\n",
    "\n",
    "    if step % eval_interval == 0:\n",
    "        avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
    "        # print('step = {0}: Average Return = {1}'.format(step, avg_return))\n",
    "        returns.append(avg_return)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65270696-356d-4030-820b-becb8e4de0b6",
   "metadata": {},
   "source": [
    "### 6) Evaluate our agent\n",
    "\n",
    "We need a way to see how good our policy is performing on our environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81252ce2-e026-45f9-beb3-ec39be014287",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8de255a7-ee0d-4b41-8444-bfc3ff381284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1863.8,\n",
       " -19983.6,\n",
       " -24979.6,\n",
       " -24974.3,\n",
       " -24959.2,\n",
       " -24964.5,\n",
       " -19978.8,\n",
       " -24979.2,\n",
       " -14927.0,\n",
       " -19932.7,\n",
       " -19902.8]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb8f7e19-7d9d-4094-978d-df08f525c691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Iterations')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "iterations = range(0, num_iterations + 1, eval_interval)\n",
    "plt.plot(iterations, returns)\n",
    "plt.ylabel('Average Return')\n",
    "plt.xlabel('Iterations')\n",
    "# plt.ylim(top=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86ccfadd-b403-46ee-9684-f99ef8eb9724",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b08e9ab5-91a7-4ab7-8ed7-4943d4641312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This game's correct word is: 'amias'\n",
      "\n",
      "RL Agent's guesses:\n",
      "l i r a s      Reward = 101\n",
      "- - - - - \n",
      "z e d a s      Reward = 100\n",
      "- - - - - \n",
      "z e d a s      Reward = -5000\n",
      "- - - - - \n",
      "z e d a s      Reward = -5000\n",
      "- - - - - \n",
      "z e d a s      Reward = -5000\n",
      "- - - - - \n",
      "z e d a s      Reward = -5000\n",
      "- - - - - \n",
      "\n",
      "Final Result:\n",
      "[[[12  9 18  1 19]\n",
      "  [26  5  4  1 19]\n",
      "  [26  5  4  1 19]\n",
      "  [26  5  4  1 19]\n",
      "  [26  5  4  1 19]\n",
      "  [26  5  4  1 19]]\n",
      "\n",
      " [[27 28 27 29 29]\n",
      "  [27 27 27 29 29]\n",
      "  [27 27 27 29 29]\n",
      "  [27 27 27 29 29]\n",
      "  [27 27 27 29 29]\n",
      "  [27 27 27 29 29]]]\n",
      "<tf_agents.environments.tf_py_environment.TFPyEnvironment object at 0x7fcd9033f9a0>\n"
     ]
    }
   ],
   "source": [
    "utils.play_a_tfagents_game(eval_env,agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7a11f90d-f2b1-4b8b-8324-eda1369e0a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_a_tfagents_game(env,agent):\n",
    "    for i in range(6):\n",
    "        if i == 0:\n",
    "            time_step = env.reset()\n",
    "            print(f\"This game's correct word is: '{env.pyenv.envs[0].gym.current_word}'\\n\")\n",
    "            print(\"RL Agent's guesses:\")\n",
    "    \n",
    "        action_step = agent.policy.action(time_step)\n",
    "        chosen_word = env.pyenv.envs[0].gym.valid_words[int(action_step.action.numpy())]\n",
    "        time_step = env.step(action_step.action)\n",
    "        for letter in chosen_word:\n",
    "            print(f\"{letter} \",end='')\n",
    "        print(\" \"*5,end='')\n",
    "        print(f\"Reward = {int(time_step.reward.numpy())}\")\n",
    "        print(\"- \"*5)\n",
    "\n",
    "    print(\"\\nFinal Result:\")\n",
    "    print(time_step[3].numpy().reshape((2,6,5)))\n",
    "    print(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "04d3eaa5-7e5c-4f8f-b67c-0406e2345471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(time_step.reward.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a8a02fb9-f5f6-4fe6-badb-8b2c82a83f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This game's correct word is: 'preys'\n",
      "\n",
      "RL Agent's guesses:\n",
      "p e n e s      Reward = 101\n",
      "- - - - - \n",
      "c r e e s      Reward = 151\n",
      "- - - - - \n",
      "c r e e s      Reward = 151\n",
      "- - - - - \n",
      "c r e e s      Reward = 151\n",
      "- - - - - \n",
      "c r e e s      Reward = 151\n",
      "- - - - - \n",
      "n a r k s      Reward = 51\n",
      "- - - - - \n",
      "\n",
      "Final Result:\n",
      "[[[16  5 14  5 19]\n",
      "  [ 3 18  5  5 19]\n",
      "  [ 3 18  5  5 19]\n",
      "  [ 3 18  5  5 19]\n",
      "  [ 3 18  5  5 19]\n",
      "  [14  1 18 11 19]]\n",
      "\n",
      " [[29 28 27 28 29]\n",
      "  [27 29 29 28 29]\n",
      "  [27 29 29 28 29]\n",
      "  [27 29 29 28 29]\n",
      "  [27 29 29 28 29]\n",
      "  [27 27 28 27 29]]]\n",
      "<tf_agents.environments.tf_py_environment.TFPyEnvironment object at 0x7f8d497848b0>\n"
     ]
    }
   ],
   "source": [
    "play_a_tfagents_game(eval_env,agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e62a98e5-8852-4d6e-ba6f-5151cf8a6529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorSpec(shape=(), dtype=tf.float32, name='reward')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_env."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce12289a-ff5f-461b-b121-d06a34955ecc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
